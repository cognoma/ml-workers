{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a logistic regression model to predict TP53 mutation from gene expression data in TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from dask_searchcv import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from vega import Vega\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import fill_spec_with_data, get_model_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We're going to be building a classifier with multiple genes filtered by two diseases \n",
    "# gene_ids = ['7157', '7158', '7159', '7161']\n",
    "# disease_acronyms = ['ACC', 'BLCA']\n",
    "\n",
    "# Information passed into the notebook is stored in environment variables\n",
    "gene_ids = os.environ['gene_ids'].split('-')\n",
    "disease_acronyms = os.environ['disease_acronyms'].split('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here is some [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) regarding the classifier and hyperparameters*\n",
    "\n",
    "*Here is some [information](https://ghr.nlm.nih.gov/gene/TP53) about TP53*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('download', 'covariates.tsv')\n",
    "covariate_df = pd.read_table(path, index_col=0)\n",
    "\n",
    "# Select acronym_x and n_mutations_log1p covariates only\n",
    "selected_cols = [col for col in covariate_df.columns if col.startswith('acronym_')]\n",
    "selected_cols.append('n_mutations_log1p')\n",
    "covariate_df = covariate_df[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by disease type\n",
    "query_string = ' | '.join(['acronym_{disease_acronym} == 1'.format(disease_acronym=acronym) for acronym in disease_acronyms])\n",
    "print(query_string)\n",
    "covariate_df.query(query_string, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "path = os.path.join('download', 'expression-matrix.tsv.bz2')\n",
    "expression_df = pd.read_table(path, index_col=0)\n",
    "\n",
    "# filter by sample_id\n",
    "expression_df[expression_df.index.isin(covariate_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "path = os.path.join('download', 'mutation-matrix.tsv.bz2')\n",
    "mutation_df = pd.read_table(path, index_col=0)\n",
    "\n",
    "# filter by sample_id\n",
    "mutation_df[mutation_df.index.isin(covariate_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The series holds Gene Mutation Status for each sample\n",
    "# Take max of mutation status, meaning if any of the genes mutated the value should be 1\n",
    "y = mutation_df[gene_ids].max(axis=1)\n",
    "y.head(6)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gene expression matrix shape: {}'.format(expression_df.shape))\n",
    "print('Covariates matrix shape: {}'.format(covariate_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set aside 10% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typically, this type of split can only be done \n",
    "# for genes where the number of mutations is large enough\n",
    "X = pd.concat([covariate_df, expression_df], axis='columns')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Here are the percentage of tumors with TP53\n",
    "y.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_feature_set_columns(X, feature_set):\n",
    "    \"\"\"\n",
    "    Select the feature set for the different models within the pipeline\n",
    "    \"\"\"\n",
    "    n_covariates = len(covariate_df.columns)\n",
    "    if feature_set == 'covariates':\n",
    "        return X[:, :n_covariates]\n",
    "    if feature_set == 'expressions':\n",
    "        return X[:, n_covariates:]\n",
    "    raise ValueError('feature_set not supported: {}'.format(feature_set))\n",
    "\n",
    "# Creates the expression features by standarizing them and running PCA\n",
    "# Because the expressions matrix is so large, we preprocess with PCA\n",
    "# The amount of variance in the data captured by ~100 components is high\n",
    "expression_features = Pipeline([\n",
    "    ('select_features', FunctionTransformer(select_feature_set_columns,\n",
    "        kw_args={'feature_set': 'expressions'})),\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('pca', PCA())\n",
    "])\n",
    "\n",
    "# Creates the covariate features by selecting and standardizing them\n",
    "covariate_features = Pipeline([\n",
    "    ('select_features', FunctionTransformer(select_feature_set_columns,\n",
    "        kw_args={'feature_set': 'covariates'})),\n",
    "    ('standardize', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net classifier and model paraemeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter Sweep for Hyperparameters\n",
    "n_components_list = [50, 100]\n",
    "regularization_alpha_list = [10 ** x for x in range(-3, 1)]\n",
    "regularization_l1_ratio = 0.15\n",
    "\n",
    "param_grids = {\n",
    "    'full': {\n",
    "        'features__expressions__pca__n_components' : n_components_list,\n",
    "        'classify__alpha': regularization_alpha_list\n",
    "    },\n",
    "    'expressions': {\n",
    "        'features__expressions__pca__n_components' : n_components_list,\n",
    "        'classify__alpha': regularization_alpha_list\n",
    "    },\n",
    "    'covariates': {\n",
    "        'classify__alpha': regularization_alpha_list\n",
    "    }\n",
    "}\n",
    "\n",
    "# Classifier: Elastic Net\n",
    "classifier = SGDClassifier(penalty='elasticnet',\n",
    "                           l1_ratio=regularization_l1_ratio,\n",
    "                           loss='log', \n",
    "                           class_weight='balanced',\n",
    "                           random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full model pipelines\n",
    "pipeline_definitions = {\n",
    "    'full': Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('expressions', expression_features),\n",
    "            ('covariates', covariate_features)\n",
    "        ])),\n",
    "        ('classify', classifier)\n",
    "    ]),\n",
    "    'expressions': Pipeline([\n",
    "        ('features', FeatureUnion([('expressions', expression_features)])),\n",
    "        ('classify', classifier)\n",
    "    ]),\n",
    "    'covariates': Pipeline([\n",
    "        ('features', FeatureUnion([('covariates', covariate_features)])),\n",
    "        ('classify', classifier)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Construct cross-validated grid searches\n",
    "cv_pipelines = dict()\n",
    "for model, pipeline in pipeline_definitions.items():\n",
    "    cv = StratifiedKFold(n_splits=3, random_state=0)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[model],\n",
    "        cv=cv,\n",
    "        n_jobs=1, \n",
    "        scoring='roc_auc',\n",
    "    )\n",
    "    cv_pipelines[model] = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the models\n",
    "for model, pipeline in cv_pipelines.items():\n",
    "    print('Fitting CV for model: {0}'.format(model))\n",
    "    start_time = time.perf_counter()\n",
    "    pipeline.fit(X=X_train, y=y_train)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed = datetime.timedelta(seconds=end_time - start_time)\n",
    "    print('\\truntime: {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best Parameters\n",
    "for model, pipeline in cv_pipelines.items():\n",
    "    print('#', model)\n",
    "    print(pipeline.best_params_)\n",
    "    print('cv_auroc = {:.3%}'.format(pipeline.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize hyperparameters performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame()\n",
    "for model, pipeline in cv_pipelines.items():\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(pipeline.cv_results_),\n",
    "        pd.DataFrame.from_records(pipeline.cv_results_['params'])\n",
    "    ], axis='columns')\n",
    "    df['feature_set'] = model\n",
    "    cv_results_df = cv_results_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validated performance heatmap\n",
    "cv_score_mat = pd.pivot_table(cv_results_df,\n",
    "                              values='mean_test_score', \n",
    "                              index='feature_set',\n",
    "                              columns='classify__alpha')\n",
    "ax = sns.heatmap(cv_score_mat, annot=True, fmt='.1%')\n",
    "ax.set_xlabel('Regularization strength multiplier (alpha)')\n",
    "ax.set_ylabel('Feature Set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use optimal hyperparameters to output ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_dict = {\n",
    "    model: {\n",
    "        'train': pipeline.decision_function(X_train),\n",
    "        'test':  pipeline.decision_function(X_test)\n",
    "    } for model, pipeline in cv_pipelines.items()\n",
    "}\n",
    "\n",
    "def get_threshold_metrics(y_true, y_pred):\n",
    "    roc_columns = ['fpr', 'tpr', 'threshold']\n",
    "    roc_items = zip(roc_columns, roc_curve(y_true, y_pred))\n",
    "    roc_df = pd.DataFrame.from_items(roc_items)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    return {'auroc': auroc, 'roc_df': roc_df}\n",
    "\n",
    "metrics_dict = {    \n",
    "    model: {\n",
    "        'train': get_threshold_metrics(y_train, y_pred_dict[model]['train']),\n",
    "        'test':  get_threshold_metrics(y_test, y_pred_dict[model]['test'])\n",
    "    } for model in y_pred_dict.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assemble the data for ROC curves\n",
    "model_order = ['full', 'expressions', 'covariates']\n",
    "\n",
    "auc_output = pd.DataFrame()\n",
    "roc_output = pd.DataFrame()\n",
    "\n",
    "for model in model_order:\n",
    "    metrics_partition = metrics_dict[model]\n",
    "    for partition, metrics in metrics_partition.items():\n",
    "        auc_output = auc_output.append(pd.DataFrame({\n",
    "            'partition': [partition],\n",
    "            'feature_set': [model],\n",
    "            'auc': metrics['auroc']\n",
    "        }))\n",
    "        roc_df = metrics['roc_df']\n",
    "        roc_output = roc_output.append(pd.DataFrame({\n",
    "            'false_positive_rate': roc_df.fpr,\n",
    "            'true_positive_rate': roc_df.tpr,\n",
    "            'partition': partition,\n",
    "            'feature_set': model\n",
    "        }))\n",
    "auc_output['legend_index'] = range(len(auc_output.index))\n",
    "\n",
    "with open('vega_specs/roc_vega_spec.json', 'r') as fp:\n",
    "    vega_spec = json.load(fp)\n",
    "\n",
    "final_spec = fill_spec_with_data(vega_spec, \n",
    "    {'roc': roc_output, 'legend_auc': auc_output})\n",
    "\n",
    "Vega(final_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the classifier coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pipelines = {\n",
    "    model: pipeline.best_estimator_\n",
    "    for model, pipeline in cv_pipelines.items()\n",
    "}\n",
    "final_classifiers = {\n",
    "    model: pipeline.named_steps['classify']\n",
    "    for model, pipeline in final_pipelines.items()\n",
    "}\n",
    "\n",
    "coef_df = pd.concat([\n",
    "    get_model_coefficients(classifier, model, covariate_df.columns)\n",
    "    for model, classifier in final_classifiers.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Signs of the coefficients by model\n",
    "pd.crosstab(coef_df.feature_set, np.sign(coef_df.weight).rename('coefficient_sign'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top standardized coefficients\n",
    "(coef_df\n",
    "    .query(\"feature_set == 'full'\")\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame()\n",
    "for model, pipeline in final_pipelines.items():\n",
    "    df = pd.DataFrame.from_items([\n",
    "        ('feature_set', model),\n",
    "        ('sample_id', X.index),\n",
    "        ('test_set', X.index.isin(X_test.index).astype(int)),\n",
    "        ('status', y),\n",
    "        ('decision_function', pipeline.decision_function(X)),\n",
    "        ('probability', pipeline.predict_proba(X)[:, 1])\n",
    "    ])    \n",
    "    predict_df = predict_df.append(df)\n",
    "\n",
    "predict_df['probability_str'] = predict_df['probability'].apply('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top predictions amongst negatives (potential hidden responders to a targeted cancer therapy)\n",
    "(predict_df\n",
    "    .sort_values('decision_function', ascending=False)\n",
    "    .query(\"status == 0 and feature_set == 'full'\")\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_predict_df = predict_df.query(\"feature_set == 'full'\")\n",
    "ax = sns.distplot(model_predict_df.query(\"status == 0\").probability, hist=False, label='Negatives')\n",
    "ax = sns.distplot(model_predict_df.query(\"status == 1\").probability, hist=False, label='Positives')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
